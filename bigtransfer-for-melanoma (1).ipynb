{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-input":true,"_kg_hide-output":true,"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2022-07-30T20:34:50.714372Z","iopub.status.busy":"2022-07-30T20:34:50.713995Z","iopub.status.idle":"2022-07-30T20:34:51.247181Z","shell.execute_reply":"2022-07-30T20:34:51.246271Z","shell.execute_reply.started":"2022-07-30T20:34:50.714340Z"},"trusted":true},"outputs":[],"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\n","\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-07-30T20:34:51.249734Z","iopub.status.busy":"2022-07-30T20:34:51.248877Z","iopub.status.idle":"2022-07-30T20:34:51.256669Z","shell.execute_reply":"2022-07-30T20:34:51.255442Z","shell.execute_reply.started":"2022-07-30T20:34:51.249694Z"},"trusted":true},"outputs":[],"source":["import tensorflow as tf\n","import matplotlib.pyplot as plt\n","import os\n","import cv2\n","from tensorflow.keras.preprocessing import image\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.optimizers import Adam"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-07-30T20:34:51.259034Z","iopub.status.busy":"2022-07-30T20:34:51.258572Z","iopub.status.idle":"2022-07-30T20:34:51.314667Z","shell.execute_reply":"2022-07-30T20:34:51.313623Z","shell.execute_reply.started":"2022-07-30T20:34:51.258997Z"},"trusted":true},"outputs":[],"source":["import numpy as np\n","SEEDS=42\n","np.random.seed(SEEDS)\n","tf.random.set_seed(SEEDS)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-07-30T20:34:51.323796Z","iopub.status.busy":"2022-07-30T20:34:51.323072Z","iopub.status.idle":"2022-07-30T20:34:59.476526Z","shell.execute_reply":"2022-07-30T20:34:59.475547Z","shell.execute_reply.started":"2022-07-30T20:34:51.323757Z"},"trusted":true},"outputs":[],"source":["training = ImageDataGenerator(rescale = 1. / 255)\n","\n","train_dataset = training.flow_from_directory(\n","    '../input/skin-cancer-malignant-vs-benign/train/',\n","    target_size=(200, 200),\n","    batch_size=32,\n","    class_mode='binary')\n","data_list = []\n","batch_index = 0\n","\n","while batch_index <= train_dataset.batch_index:\n","    data = train_dataset.next()\n","    data_list.append(data[0])\n","    batch_index = batch_index + 1\n","\n","# now, data_array is the numeric data of whole images\n","data_array = np.asarray(data_list)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-07-30T20:34:59.478618Z","iopub.status.busy":"2022-07-30T20:34:59.478014Z","iopub.status.idle":"2022-07-30T20:35:01.641236Z","shell.execute_reply":"2022-07-30T20:35:01.640132Z","shell.execute_reply.started":"2022-07-30T20:34:59.478581Z"},"trusted":true},"outputs":[],"source":["validation = ImageDataGenerator(rescale = 1. / 255)\n","\n","val_dataset = training.flow_from_directory(\n","    '../input/skin-cancer-malignant-vs-benign/test/',\n","    target_size=(200, 200),\n","    batch_size=32,\n","    class_mode='binary')\n","data_list = []\n","batch_index = 0\n","\n","while batch_index <= val_dataset.batch_index:\n","    data = val_dataset.next()\n","    data_list.append(data[0])\n","    batch_index = batch_index + 1\n","\n","# now, data_array is the numeric data of whole images\n","val_array = np.asarray(data_list, dtype=object)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-07-30T20:35:01.642874Z","iopub.status.busy":"2022-07-30T20:35:01.642533Z","iopub.status.idle":"2022-07-30T20:35:01.650068Z","shell.execute_reply":"2022-07-30T20:35:01.649044Z","shell.execute_reply.started":"2022-07-30T20:35:01.642840Z"},"trusted":true},"outputs":[],"source":["RESIZE_TO = 384\n","CROP_TO = 224\n","BATCH_SIZE = 16\n","STEPS_PER_EPOCH = (2637/32)\n","AUTO = tf.data.experimental.AUTOTUNE  # optimise the pipeline performance\n","NUM_CLASSES = 9\n","# number of classes\n","SCHEDULE_LENGTH = (\n","    500  # we will train on lower resolution images and will still attain good results\n",")\n","SCHEDULE_BOUNDARIES = [\n","    200,\n","    300,\n","    400,\n","] \n","# more the dataset size the schedule length increase"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-output":true,"execution":{"iopub.execute_input":"2022-07-30T20:35:01.652821Z","iopub.status.busy":"2022-07-30T20:35:01.651886Z","iopub.status.idle":"2022-07-30T20:35:20.438482Z","shell.execute_reply":"2022-07-30T20:35:20.437350Z","shell.execute_reply.started":"2022-07-30T20:35:01.652786Z"},"trusted":true},"outputs":[],"source":["!pip install \"tensorflow>=1.7.0\"\n","!pip install tensorflow-hub\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-07-30T20:35:20.441907Z","iopub.status.busy":"2022-07-30T20:35:20.441543Z","iopub.status.idle":"2022-07-30T20:35:57.145095Z","shell.execute_reply":"2022-07-30T20:35:57.144157Z","shell.execute_reply.started":"2022-07-30T20:35:20.441866Z"},"trusted":true},"outputs":[],"source":["import tensorflow_hub as hub\n","bit_model_url = \"https://tfhub.dev/google/bit/m-r50x1/1\"\n","bit_module = hub.KerasLayer(bit_model_url)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-07-30T20:35:57.146914Z","iopub.status.busy":"2022-07-30T20:35:57.146551Z","iopub.status.idle":"2022-07-30T20:35:57.157924Z","shell.execute_reply":"2022-07-30T20:35:57.157056Z","shell.execute_reply.started":"2022-07-30T20:35:57.146877Z"},"trusted":true},"outputs":[],"source":["from tensorflow import keras\n","class MyBiTModel(keras.Model):\n","    def __init__(self, num_classes, module, **kwargs):\n","        super().__init__(**kwargs)\n","\n","        self.num_classes = num_classes\n","        self.head = keras.layers.Dense(num_classes, kernel_initializer=\"zeros\")\n","        self.bit_model = module\n","\n","    def call(self, images):\n","        bit_embedding = self.bit_model(images)\n","        return self.head(bit_embedding)\n","\n","\n","model = MyBiTModel(num_classes=NUM_CLASSES, module=bit_module)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-07-30T20:35:57.161955Z","iopub.status.busy":"2022-07-30T20:35:57.161649Z","iopub.status.idle":"2022-07-30T20:35:57.170250Z","shell.execute_reply":"2022-07-30T20:35:57.169400Z","shell.execute_reply.started":"2022-07-30T20:35:57.161932Z"},"trusted":true},"outputs":[],"source":["learning_rate = 0.003 * BATCH_SIZE / 512\n","\n","# Decay learning rate by a factor of 10 at SCHEDULE_BOUNDARIES.\n","lr_schedule = keras.optimizers.schedules.PiecewiseConstantDecay(\n","    boundaries=SCHEDULE_BOUNDARIES,\n","    values=[\n","        learning_rate,\n","        learning_rate * 0.1,\n","        learning_rate * 0.01,\n","        learning_rate * 0.001,\n","    ],\n",")\n","optimizer = keras.optimizers.SGD(learning_rate=lr_schedule, momentum=0.9)\n","\n","loss_fn = keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-07-30T20:35:57.172273Z","iopub.status.busy":"2022-07-30T20:35:57.171864Z","iopub.status.idle":"2022-07-30T20:35:57.183695Z","shell.execute_reply":"2022-07-30T20:35:57.182829Z","shell.execute_reply.started":"2022-07-30T20:35:57.172226Z"},"trusted":true},"outputs":[],"source":["model.compile(optimizer=optimizer, loss=loss_fn, metrics=['accuracy'])"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-07-30T20:35:57.185836Z","iopub.status.busy":"2022-07-30T20:35:57.185333Z","iopub.status.idle":"2022-07-30T20:35:57.192307Z","shell.execute_reply":"2022-07-30T20:35:57.191323Z","shell.execute_reply.started":"2022-07-30T20:35:57.185792Z"},"trusted":true},"outputs":[],"source":["train_callbacks = [\n","   keras.callbacks.EarlyStopping(\n","       monitor=\"val_accuracy\", patience=2, restore_best_weights=True   )\n"," ]"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-07-30T20:35:57.194486Z","iopub.status.busy":"2022-07-30T20:35:57.194068Z","iopub.status.idle":"2022-07-30T20:37:49.465848Z","shell.execute_reply":"2022-07-30T20:37:49.464877Z","shell.execute_reply.started":"2022-07-30T20:35:57.194449Z"},"trusted":true},"outputs":[],"source":["import time\n","start = time.time()\n","history = model.fit(\n","    train_dataset,\n","    batch_size=32,\n","    epochs=50,\n","    steps_per_epoch=STEPS_PER_EPOCH,\n","    validation_data=val_dataset,\n","    callbacks=train_callbacks\n","    \n","    \n"," \n","    \n",")\n","print(\"Total time: \", time.time() - start, \"seconds\")\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-07-30T20:46:49.817202Z","iopub.status.busy":"2022-07-30T20:46:49.816758Z","iopub.status.idle":"2022-07-30T20:46:50.030126Z","shell.execute_reply":"2022-07-30T20:46:50.029180Z","shell.execute_reply.started":"2022-07-30T20:46:49.817162Z"},"trusted":true},"outputs":[],"source":["import matplotlib.pyplot as plt\n","plt.plot(history.history['accuracy'])\n","plt.plot(history.history['val_accuracy'])\n","plt.plot(history.history['loss'])\n","plt.plot(history.history['val_loss'])\n","plt.title('model accuracy')\n","plt.ylabel('accuracy')\n","plt.xlabel('epoch')\n","plt.legend(['train_accuracy', 'val_accuracy', 'train_loss', 'val_loss'], bbox_to_anchor =(0.65, 1.00))\n","plt.show()\n","plt.savefig(\"bit.png\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":174469,"sourceId":505351,"sourceType":"datasetVersion"}],"dockerImageVersionId":30213,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"}},"nbformat":4,"nbformat_minor":4}
